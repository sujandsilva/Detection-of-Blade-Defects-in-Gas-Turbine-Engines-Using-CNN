{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d384bfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created at C:\\Users\\admin\\OneDrive\\Desktop\\ML projects\\Engine defects\\archive (1)\\Aero-engine_defect-detect_new\\defect_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Defining the paths\n",
    "base_dir = 'C:\\\\Users\\\\admin\\\\OneDrive\\\\Desktop\\\\ML projects\\\\Engine defects\\\\archive (1)\\\\Aero-engine_defect-detect_new'\n",
    "images_dir = os.path.join(base_dir, 'images')\n",
    "labels_dir = os.path.join(base_dir, 'labels')\n",
    "\n",
    "# loading the CSV file\n",
    "csv_file = os.path.join(base_dir, 'defect_data.csv')\n",
    "\n",
    "# Function to process a directory\n",
    "def process_directory(image_subdir, label_subdir, csv_writer):\n",
    "    image_folder = os.path.join(images_dir, image_subdir)\n",
    "    label_folder = os.path.join(labels_dir, label_subdir)\n",
    "\n",
    "    for image_filename in os.listdir(image_folder):\n",
    "        if image_filename.endswith('.jpg') or image_filename.endswith('.png'):\n",
    "            image_path = os.path.join(image_folder, image_filename)\n",
    "            label_filename = image_filename.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "            label_path = os.path.join(label_folder, label_filename)\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as label_file:\n",
    "                    for line in label_file:\n",
    "                        parts = line.strip().split()\n",
    "                        defect_type = parts[0]\n",
    "                        x1, y1, x2, y2 = parts[1:]\n",
    "                        csv_writer.writerow([image_path, defect_type, x1, y1, x2, y2])\n",
    "\n",
    "# Creating the CSV file\n",
    "with open(csv_file, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['image_path', 'defect_type', 'x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "    # Process train and val directories\n",
    "    process_directory('train', 'train', csv_writer)\n",
    "    process_directory('val', 'val', csv_writer)\n",
    "\n",
    "print(f\"CSV file created at {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432a26b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.3484 - loss: 1.4563 - val_accuracy: 0.6579 - val_loss: 0.9650\n",
      "Epoch 2/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.5553 - loss: 1.0658 - val_accuracy: 0.6184 - val_loss: 0.9691\n",
      "Epoch 3/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.5827 - loss: 0.9329 - val_accuracy: 0.6053 - val_loss: 0.9312\n",
      "Epoch 4/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.5968 - loss: 0.8900 - val_accuracy: 0.6316 - val_loss: 0.8785\n",
      "Epoch 5/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.6295 - loss: 0.8624 - val_accuracy: 0.6711 - val_loss: 1.1049\n",
      "Epoch 6/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.6945 - loss: 0.7466 - val_accuracy: 0.6711 - val_loss: 1.4721\n",
      "Epoch 7/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.7077 - loss: 0.6302 - val_accuracy: 0.6842 - val_loss: 1.4161\n",
      "Epoch 8/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.7660 - loss: 0.5207 - val_accuracy: 0.7237 - val_loss: 1.7584\n",
      "Epoch 9/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.8001 - loss: 0.4809 - val_accuracy: 0.7763 - val_loss: 2.1439\n",
      "Epoch 10/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.8345 - loss: 0.3477 - val_accuracy: 0.7368 - val_loss: 2.0201\n",
      "Epoch 11/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.8089 - loss: 0.3873 - val_accuracy: 0.7368 - val_loss: 2.2538\n",
      "Epoch 12/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.8275 - loss: 0.3841 - val_accuracy: 0.7763 - val_loss: 2.2534\n",
      "Epoch 13/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.8528 - loss: 0.3369 - val_accuracy: 0.7632 - val_loss: 2.5097\n",
      "Epoch 14/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.8774 - loss: 0.2747 - val_accuracy: 0.7763 - val_loss: 2.7468\n",
      "Epoch 15/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.8829 - loss: 0.2948 - val_accuracy: 0.8026 - val_loss: 2.9869\n",
      "Epoch 16/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.9002 - loss: 0.2314 - val_accuracy: 0.7895 - val_loss: 3.0086\n",
      "Epoch 17/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.8366 - loss: 0.3139 - val_accuracy: 0.7632 - val_loss: 2.8968\n",
      "Epoch 18/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8499 - loss: 0.2760 - val_accuracy: 0.7895 - val_loss: 3.6915\n",
      "Epoch 19/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.8578 - loss: 0.3132 - val_accuracy: 0.7895 - val_loss: 3.0521\n",
      "Epoch 20/20\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.8797 - loss: 0.2758 - val_accuracy: 0.8026 - val_loss: 3.5216\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294ms/step - accuracy: 0.8193 - loss: 2.8385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.5216310024261475\n",
      "Validation Accuracy: 0.8026315569877625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Loading the CSV file\n",
    "csv_file = 'C:\\\\Users\\\\admin\\\\OneDrive\\\\Desktop\\\\ML projects\\\\Engine defects\\\\archive (1)\\\\Aero-engine_defect-detect_new\\\\defect_data.csv'\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images(data, image_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for index, row in data.iterrows():\n",
    "        image_path = row['image_path']\n",
    "        defect_type = row['defect_type']\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, image_size)\n",
    "        images.append(image)\n",
    "        labels.append(defect_type)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels).astype('float32')\n",
    "    return images, labels\n",
    "\n",
    "# Load and preprocess images and labels\n",
    "image_size = (128, 128)\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "train_data = data[data['image_path'].str.contains('train')]\n",
    "val_data = data[data['image_path'].str.contains('val')]\n",
    "X_train, y_train = load_images(train_data, image_size=image_size)\n",
    "X_val, y_val = load_images(val_data, image_size=image_size)\n",
    "\n",
    "# Normalizing pixel values to between 0 and 1\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "# Converting labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=4)\n",
    "\n",
    "# Creating the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluating the model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Save the model\n",
    "model.save('defect_detection_model.h5')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
